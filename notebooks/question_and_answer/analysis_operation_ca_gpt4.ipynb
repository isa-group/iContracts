{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Analysis"
      ],
      "metadata": {
        "id": "7ybdZ5XahFcM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RF9xoNH7m_ul"
      },
      "outputs": [],
      "source": [
        "! pip install langchain\n",
        "! pip install openai\n",
        "! pip install tiktoken\n",
        "! pip install tqdm\n",
        "! pip install chromadb\n",
        "! pip install langchain_experimental\n",
        "! pip install langchain_openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "9gPZtfWtm_uo"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from typing import List, Union\n",
        "\n",
        "import chromadb\n",
        "\n",
        "from langchain.pydantic_v1 import Field, BaseModel\n",
        "from langchain.chains.openai_functions import create_structured_output_chain\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.text_splitter import MarkdownHeaderTextSplitter\n",
        "from langchain_experimental.text_splitter import SemanticChunker\n",
        "from langchain_openai.embeddings import OpenAIEmbeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "yKd2oxSrahsy"
      },
      "outputs": [],
      "source": [
        "# add your api key\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kq2WpmQNahsy"
      },
      "source": [
        "# Populate the Database using the Knowledge Base"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Y1ogcns2hCyJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "SEZRTA5TmMBz"
      },
      "outputs": [],
      "source": [
        "client = chromadb.Client(chromadb.Settings(allow_reset=True))\n",
        "client.reset()\n",
        "\n",
        "# create collection to store github general terms documents\n",
        "collection = client.get_or_create_collection(\"github-customer-agreement\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "M-lTOT0Gahsz"
      },
      "outputs": [],
      "source": [
        "headers_to_split_on = [\n",
        "    (\"#\", \"Header 1\"),\n",
        "    (\"##\", \"Header 2\"),\n",
        "    (\"###\", \"Header 3\"),\n",
        "]\n",
        "\n",
        "markdown_splitter = MarkdownHeaderTextSplitter(headers_to_split_on=headers_to_split_on)\n",
        "semantic_chunker = SemanticChunker(OpenAIEmbeddings())\n",
        "\n",
        "def chunk_markdown(document: str):\n",
        "    \"\"\"Split ducument based on Markdown structure\"\"\"\n",
        "    markdown_splitter = MarkdownHeaderTextSplitter(headers_to_split_on=headers_to_split_on)\n",
        "    return markdown_splitter.split_text(document)\n",
        "\n",
        "def chunk_semanticly(document: str):\n",
        "    \"\"\"Split document grouping sentences semanticly closed to each other\"\"\"\n",
        "    return semantic_chunker.create_documents([document])\n",
        "\n",
        "def read_and_chunk(path: str, chunking_function=chunk_semanticly):\n",
        "    \"\"\"Read file and chunck it\n",
        "\n",
        "    Returns: a list of documents.\n",
        "    \"\"\"\n",
        "    with open(path, \"r\") as f:\n",
        "        document = f.read()\n",
        "    return chunking_function(document)\n",
        "\n",
        "def upsert_documents(document_id, documents):\n",
        "    \"\"\"Insert or updates a list of documents\"\"\"\n",
        "    collection.upsert(\n",
        "        documents=[document.page_content for document in documents],\n",
        "        metadatas=[document.metadata for document in documents],\n",
        "        ids=[\"{}-{}\".format(document_id, i) for i in range(len(documents))]\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ZbphFtHhQhnJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a05938da-9ff0-45fa-a795-7efec919401f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/root/.cache/chroma/onnx_models/all-MiniLM-L6-v2/onnx.tar.gz: 100%|██████████| 79.3M/79.3M [00:01<00:00, 46.7MiB/s]\n"
          ]
        }
      ],
      "source": [
        "knoledge_base = [\n",
        "    'github-general-terms.md',\n",
        "    'github-data-protection.md'\n",
        "]\n",
        "\n",
        "for document_path in knoledge_base:\n",
        "    documents = read_and_chunk(document_path, chunking_function=chunk_markdown)\n",
        "    upsert_documents(document_path, documents)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "collection.count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ApmrBe5texXL",
        "outputId": "dbf7f78d-a8dc-4807-d18f-4570fba71d26"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "44"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f8S15_1Pahs0"
      },
      "source": [
        "# Chain of Thought QA using Vector Database with Knowledge Base"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "CNORktnqm_up"
      },
      "outputs": [],
      "source": [
        "class Background(BaseModel):\n",
        "    \"\"\"Background explaining user question\"\"\"\n",
        "    background: str = Field(..., description=\"Background explaining user questions\")\n",
        "\n",
        "class Thought(BaseModel):\n",
        "    \"\"\"A thought about user question\"\"\"\n",
        "    thought: str = Field(..., description=\"A thought about user question\")\n",
        "    flawed: bool = Field(..., description=\"Whether or not the thought is flawed or misleading\")\n",
        "    helpful: bool = Field(..., description=\"Whether or not the thought is helpful to solve user question\")\n",
        "\n",
        "class Answer(BaseModel):\n",
        "    \"\"\"The answer to user question\"\"\"\n",
        "    awnser: str = Field(..., description=\"Answer to user question\")\n",
        "    score: int = Field(..., description=\"Score from 1 to 10 on how correct the anwser is\", min_value=1, max_value=10)\n",
        "\n",
        "class ChainOfThought(BaseModel):\n",
        "    \"\"\"A chain of thoughts to answer user question\"\"\"\n",
        "    background: Background = Field(..., description=\"Background explaining user questions\")\n",
        "    thoughts: List[Thought] = Field(..., description=\"List of thoughts about user question\")\n",
        "    answer: Answer = Field(..., description=\"The answer to user question\")\n",
        "\n",
        "class ChainOfThoughtBuilder():\n",
        "    \"\"\"Build a chain of thought (CoT) to anwser a questions using a LLM\"\"\"\n",
        "\n",
        "    def __init__(self, llm, verbose=False):\n",
        "        self.prompt = ChatPromptTemplate.from_messages([\n",
        "            (\"system\", \"You are the most intelligent person in the world.\"\n",
        "                \"\"\n",
        "                \"You will receive a prize if you follow ALL these rules:\"\n",
        "                \"- First, establish a detailed background useful to anwser the user question.\"\n",
        "                \"- Each thought must include whether it is relevant and whether it is helpful.\"\n",
        "                \"- Continue to add thoughts until you can confidently answer the question.\"\n",
        "                \"- The anwser must be scored accurately and honestly.\"),\n",
        "            (\"human\", 'Useful context: {context}'),\n",
        "            (\"human\", 'User question: \"\"\"{question}\"\"\"'),\n",
        "        ])\n",
        "        self.chain = create_structured_output_chain(ChainOfThought, llm, self.prompt, verbose=verbose)\n",
        "\n",
        "    def build(self, question: str, context: str = None):\n",
        "        return self.chain.run(context=context, question=question)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "lXJI9J3oo05d"
      },
      "outputs": [],
      "source": [
        "def cot_to_markdown(cot: ChainOfThought, question: str, top_documents: List[str], metadatas: List[dict]):\n",
        "    \"\"\"Convert a ChainOfThought to markdown\"\"\"\n",
        "    md = \"# Top documents\\n\"\n",
        "    for i, (document, metadata) in enumerate(zip(top_documents, metadatas)):\n",
        "        md += \"## Document \" + str(i) + \": \" + \" - \".join(metadata.values()) + \"\\n\"\n",
        "        md += document + \"\\n\\n\"\n",
        "\n",
        "    md += \"# \" + question + \"\\n\"\n",
        "    md += \"## Background\\n\"\n",
        "    md += cot.background.background + \"\\n\\n\"\n",
        "\n",
        "    md += \"## Thoughts\\n\"\n",
        "    for thought in cot.thoughts:\n",
        "        md += \"- \" + thought.thought + \"\\n\"\n",
        "        md += \"  - Flawed: \" + str(thought.flawed) + \"\\n\"\n",
        "        md += \"  - Helpful: \" + str(thought.helpful) + \"\\n\\n\"\n",
        "\n",
        "    md += \"## Answer\\n\"\n",
        "    md += \"- \" + cot.answer.awnser + \"\\n\"\n",
        "    md += \"  - Score: \" + str(cot.answer.score) + \"\\n\\n\"\n",
        "\n",
        "    return md\n",
        "\n",
        "def search_topn_documents(query, n_results=5):\n",
        "    \"\"\"Return the top N document given a query text\"\"\"\n",
        "    return collection.query(\n",
        "        query_texts=query,\n",
        "        n_results=n_results\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pb0Mwtk0m_uq"
      },
      "source": [
        "# Customer Agreement relevant questions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Y7T7PmrX3zIm"
      },
      "outputs": [],
      "source": [
        "questions = [\n",
        "    \"As a customer, can I share the product or service with third parties?\",\n",
        "    \"As a customer, can I modify the source code of the product or service to my liking?\",\n",
        "    \"Can the supplier make modifications to the products or services?\",\n",
        "    \"Does the contract provide any protection for confidential customer information?\",\n",
        "    \"Does the customer retain ownership of the data he provides to the supplier?\",\n",
        "    \"Are the rights of use the supplier receives over the customer's data limited to what is strictly necessary?\",\n",
        "    \"Does the provider commit to any security standards or practices regarding customer content?\",\n",
        "    \"Are the licenses received by the supplier on the customer's intellectual property limited?\",\n",
        "    \"Does the supplier have to delete personal information after the end of the contract?\",\n",
        "    \"Does the supplier indemnify the customer for infringement of third party intellectual property?\",\n",
        "    \"Are the customer's indemnification obligations limited in third party claims?\",\n",
        "    \"Is the customer's ability to confront the supplier or any other party limited?\",\n",
        "    \"Does the supplier have a liability limit of 12 months' quota or higher?\",\n",
        "    \"What limits of liability against consequential damages does the supplier have?\",\n",
        "    \"If the supplier indemnifies for infringement of third party intellectual property, is it exempt from the limit of liability?\",\n",
        "    \"Is the customer's liability limited?\",\n",
        "    \"Does the customer have any right to terminate the agreement?\",\n",
        "    \"If the contract is self-renewing can the customer opt out at that time?\",\n",
        "    \"Does the customer have any liability to pay taxes?\",\n",
        "    \"What rights does the customer have regarding data migration?\",\n",
        "    \"Is the contract renewal automatic or does it need to be initiated by the customer?\",\n",
        "    \"What is the mandatory governing law?\",\n",
        "    \"Is the mandatory headquarters located within the United States?\",\n",
        "    \"Is the customer's ability to develop or procure similar products or services from other suppliers limited?\",\n",
        "    \"Who is responsible for ensuring that the services function properly?\",\n",
        "    \"Can the customer notify the supplier via email?\",\n",
        "    \"To answer the following questions we must simulate a real context. In this case, we consider a customer with an annual subscription, enjoys since January 1, 2024 of the provider's services and the total amount of the fees is 528$. What is the validity period of the contract?\",\n",
        "    \"To answer the following questions we must simulate a real context. In this case, we consider a customer with an annual subscription, enjoys since January 1, 2024 of the provider's services and the total amount of the fees is 528$. When must the customer terminate the contract in order not to renew the license or subscription to the services?\",\n",
        "    \"To answer the following questions we must simulate a real context. In this case, we consider a customer with an annual subscription, enjoys since January 1, 2024 of the provider's services and the total amount of the fees is 528$. When will the customer no longer be able to use the service if the contract is terminated?\",\n",
        "    \"To answer the following questions we must simulate a real context. In this case, we consider a customer with an annual subscription, enjoys since January 1, 2024 of the provider's services and the total amount of the fees is 528$. The customer did not pay the previous fee. How much should the customer pay this month?\",\n",
        "    \"To answer the following questions we must simulate a real context. In this case, we consider a customer with an annual subscription, enjoys since January 1, 2024 of the provider's services and the total amount of the fees is 528$. An incident has occurred, what is the provider's responsibility?\",\n",
        "    \"To answer the following questions we must simulate a real context. In this case, we consider a customer with an annual subscription, enjoys since January 1, 2024 of the provider's services and the total amount of the fees is 528$. Until what day can the customer request data migration if the contract has been terminated?\",\n",
        "    \"To answer the following questions we must simulate a real context. In this case, we consider a customer with an annual subscription, enjoys since January 1, 2024 of the provider's services and the total amount of the fees is 528$. For how long are the pricing conditions of this contract maintained?\"\n",
        "    ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DFVTn9PYo5XZ"
      },
      "outputs": [],
      "source": [
        "llm = ChatOpenAI(model=\"gpt-4-1106-preview\", temperature=0)\n",
        "cot_builder = ChainOfThoughtBuilder(llm, verbose=True)\n",
        "\n",
        "for i, question in enumerate(questions):\n",
        "  top_documents = search_topn_documents(question, n_results=44)\n",
        "  cot = cot_builder.build(question, context='\\n'.join(top_documents['documents'][0]))\n",
        "  markdown = cot_to_markdown(cot, question, top_documents['documents'][0], top_documents['metadatas'][0])\n",
        "  with open(f\"question_{i}.md\", \"w\") as f:\n",
        "      f.write(markdown)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}